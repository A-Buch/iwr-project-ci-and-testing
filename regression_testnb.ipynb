{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#  import time\n",
    "#  from multiprocess import Pool\n",
    "import numpy as np\n",
    "import iris\n",
    "import iris.coord_categorisation as icc\n",
    "#  from scipy import stats\n",
    "#  import dask as da\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started at: 2019-03-07 11:45:12.957829\n",
      "Creating Container for Slopes\n"
     ]
    }
   ],
   "source": [
    "#  specify paths\n",
    "out_script = '/home/bschmidt/scripts/detrending/output/regr.out'\n",
    "source_path_data = '/home/bschmidt/data/test_data_tas.nc4'\n",
    "source_path_gmt = '/home/bschmidt/data/test_gmt.nc4'\n",
    "dest_path = '/home/bschmidt/data/'\n",
    "\n",
    "#  Get jobs starting time\n",
    "STIME = datetime.now()\n",
    "with open(out_script, 'w') as out:\n",
    "    out.write('Job started at: ' + str(STIME) + '\\n')\n",
    "print('Job started at: ' + str(STIME))\n",
    "\n",
    "#  load data\n",
    "gmt = iris.load_cube(source_path_gmt)\n",
    "#  icc.add_day_of_year(gmt, 'time')\n",
    "#  print(gmt)\n",
    "data = iris.load_cube(source_path_data)\n",
    "icc.add_day_of_year(data, 'time')\n",
    "#  print(data)\n",
    "\n",
    "#  Get dayofyear-vectors of gmt and data\n",
    "doys_cube = data.coord('day_of_year').points\n",
    "#  print(doys_cube)\n",
    "doys = gmt.coord('day_of_year').points\n",
    "#print('Days of Year are:\\n')\n",
    "#print(doys)\n",
    "\n",
    "#  Create numpy arrays as containers for regression output\n",
    "print('Creating Container for Slopes')\n",
    "slope = np.ones((366,\n",
    "                  data.coord('latitude').shape[0],\n",
    "                  data.coord('longitude').shape[0]), dtype=np.float64)\n",
    "intercept=slope\n",
    "r_value=slope\n",
    "p_value=slope\n",
    "std_err=slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_doy(doy):\n",
    "    # loop over lon and lat and calculate regression\n",
    "    # write that into container\n",
    "    gmt_day = gmt[doys == doy].data\n",
    "    #A = np.vstack([gmt_day, np.ones(len(gmt_day))]).T\n",
    "    print('\\nDayofYear is:\\n' + str(doy))\n",
    "    for yx_slice in data.slices(['day_of_year']):\n",
    "        #slope, intercept = np.linalg.lstsq(A, yx_slice[doys == doy].data, rcond=None)[0]\n",
    "        s, i, r, p, sd = stats.linregress(gmt_day[1:-1],yx_slice[doys == doy].data[1:-1])\n",
    "        #print('\\nSlope is:\\n')\n",
    "        #print(slope)\n",
    "        #print('\\nIntercept is:\\n')\n",
    "        #print(intercept)\n",
    "        #print('\\nDayofYear is:\\n')\n",
    "        #print(doy)\n",
    "        lat = int(np.where(data.coord('latitude').points == yx_slice.coord('latitude').points)[0])\n",
    "        #print('\\nLatitude is:\\n')\n",
    "        #print(lat)\n",
    "        lon = int(np.where(data.coord('longitude').points == yx_slice.coord('longitude').points)[0])\n",
    "        #print('\\nLongitude is:\\n')\n",
    "        #print(lon)\n",
    "        #  write regression output to containers\n",
    "        slope[doy-1, lat, lon] = s\n",
    "        intercept[doy-1, lat, lon] = i\n",
    "        r_value[doy-1, lat, lon] = r\n",
    "        p_value[doy-1, lat, lon] = p\n",
    "        std_err[doy-1, lat, lon] = sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with regression Calculations\n",
      "\n",
      "Time elapsed 679.897469 seconds!\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import shutil\n",
    "\n",
    "#  Get jobs starting time\n",
    "STIME = datetime.now()\n",
    "\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "memmap = list()\n",
    "for obj in ['slope', 'intercept', 'r_value', 'p_value', 'std_err']:\n",
    "    memmap.append(os.path.join(folder, obj + '_memmap'))\n",
    "    dump(eval(obj), memmap[-1])\n",
    "    #slopes_memmap = np.memmap(slopes_memmap, dtype=slopes.dtype, shape=slopes.shape, mode='w+')\n",
    "\n",
    "slope = load(memmap[0], mmap_mode='r+')\n",
    "intercept = load(memmap[1], mmap_mode='r+')\n",
    "r_value = load(memmap[2], mmap_mode='r+')\n",
    "p_value = load(memmap[3], mmap_mode='r+')\n",
    "std_err = load(memmap[4], mmap_mode='r+')\n",
    "\n",
    "# loop over dayofyear-vector, then \n",
    "print('Start with regression Calculations\\n')\n",
    "\n",
    "joblib.Parallel(n_jobs=4)(\n",
    "    joblib.delayed(regr_doy)(doy) for doy in np.unique(doys))\n",
    "\n",
    "FTIME = datetime.now()#\n",
    "duration = FTIME - STIME\n",
    "print('Time elapsed ' + str(duration.total_seconds()) + ' seconds!')\n",
    "\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(folder)\n",
    "except:  # noqa\n",
    "    print('Could not clean-up automatically.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished at: 2019-03-07 11:56:41.931396\n",
      "Time elapsed 0.0 hours!\n"
     ]
    }
   ],
   "source": [
    "#  Create dayofyear coordinate\n",
    "doy_coord = iris.coords.DimCoord(range(1,367))\n",
    "for obj in ['slope', 'intercept', 'r_value', 'p_value', 'std_err']:\n",
    "    dest_path_obj = os.path.join(dest_path, 'test_' + data.name() + '_' + obj + '.nc4')\n",
    "    #  wrap iris cube container around data\n",
    "    cube = iris.cube.Cube(eval(obj),\n",
    "                        dim_coords_and_dims=[(doy_coord, 0),\n",
    "                                             (data.coord('latitude'), 1),\n",
    "                                             (data.coord('longitude'), 2),\n",
    "                                            ])\n",
    "    iris.fileformats.netcdf.save(cube, dest_path_obj)\n",
    "\n",
    "# Get jobs finishing time\n",
    "FTIME = datetime.now()\n",
    "with open(out_script, 'a') as out:\n",
    "    out.write('Job finished at: ' + str(FTIME) + '\\n')\n",
    "print('Job finished at: ' + str(FTIME))\n",
    "duration = FTIME - STIME\n",
    "print('Time elapsed ' +\n",
    "      str(divmod(duration.total_seconds(), 3600)[0]) +\n",
    "      ' hours!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
